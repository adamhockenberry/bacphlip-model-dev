{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SearchIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.metrics import average_precision_score, confusion_matrix,\\\n",
    "                            precision_recall_curve, roc_curve, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_file = '../../Data/model_data/phage_data_nmicro2017/processed_benchmark_set.csv'\n",
    "hmm_results_dir = '../../Data/model_data/phage_data_nmicro2017/hmmsearch_out/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting shape: (1057, 22)\n",
      "New shape (should be identical): (1057, 22)\n",
      "New shape (+1): (1057, 23)\n"
     ]
    }
   ],
   "source": [
    "###Read in the dataset and double check that analysis is limited to empirically defined data\n",
    "df = pd.read_csv(benchmark_file, index_col=0)\n",
    "print('Starting shape:', df.shape)\n",
    "df = df[df['Temperate (empirical)'] != 'Unspecified']\n",
    "print('New shape (should be identical):', df.shape)\n",
    "\n",
    "###Add in my identifier\n",
    "df['Identifier_AJH'] = ''  \n",
    "df.at[df[df['Database source'] == 'NCBI RefSeq'].index, 'Identifier_AJH'] =\\\n",
    "                    df[df['Database source'] == 'NCBI RefSeq']['RefSeq accession number']\n",
    "df.at[df[df['Database source'] == 'Actinobacteriophage_785'].index, 'Identifier_AJH'] =\\\n",
    "                    df[df['Database source'] == 'Actinobacteriophage_785']['Virus identifier used for the analysis'].str.split('_').str[0]\n",
    "print('New shape (+1):', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1057, 371)\n"
     ]
    }
   ],
   "source": [
    "###Read through all of the hmmsearch files to accumulate a growing presence/absence dataframe\n",
    "file_ending = '.hmmsearch.out'\n",
    "growing_df = pd.DataFrame()\n",
    "for index in df.index:\n",
    "    if df.loc[index]['Database source'] == 'NCBI RefSeq':\n",
    "        file_name = df.loc[index]['RefSeq accession number'] + file_ending\n",
    "    elif df.loc[index]['Database source'] == 'Actinobacteriophage_785':\n",
    "        file_name = df.loc[index]['Virus identifier used for the analysis'].split('_')[0].lower() + file_ending\n",
    "#     print(file_name)\n",
    "    try:\n",
    "        with open(hmm_results_dir + file_name, 'r') as infile:\n",
    "            results = list(SearchIO.parse(infile, 'hmmer3-text'))\n",
    "            simple_res = []\n",
    "            for i in results:\n",
    "                if len(i.hits) > 0:\n",
    "                    simple_res.append((i.id, 1))\n",
    "                else:\n",
    "                    simple_res.append((i.id, 0))\n",
    "        single_df = pd.DataFrame(dict(simple_res), index=[index])\n",
    "        growing_df = pd.concat([growing_df, single_df])\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "print(growing_df.shape)\n",
    "\n",
    "###Add that to the main dataframe\n",
    "full_df = df.join(growing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training and testing dataframes: (634, 394) (423, 394)\n",
      "Shape of training and testing labels: (634, 1) (423, 1)\n"
     ]
    }
   ],
   "source": [
    "###Split into training and testing sets\n",
    "train_df, test_df = train_test_split(full_df, train_size=0.6,\\\n",
    "                                     random_state=42)\n",
    "print('Shape of training and testing dataframes:', train_df.shape, test_df.shape)\n",
    "\n",
    "###Set up the machine-learning training and test sets\n",
    "ml_df_train = train_df[train_df.columns[23:]]\n",
    "ml_df_test = test_df[test_df.columns[23:]]\n",
    "\n",
    "###And labels\n",
    "training_labels = pd.DataFrame(index=train_df.index)\n",
    "training_labels['binary'] = 0\n",
    "training_labels.at[train_df[train_df['Temperate (empirical)']=='yes'].index, 'binary'] = 1\n",
    "\n",
    "testing_labels = pd.DataFrame(index=test_df.index)\n",
    "testing_labels['binary'] = 0\n",
    "testing_labels.at[test_df[test_df['Temperate (empirical)']=='yes'].index, 'binary'] = 1\n",
    "\n",
    "print('Shape of training and testing labels:', training_labels.shape, testing_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop features that are likely to be noise\n",
    "\n",
    "My goal in semi-rationally selecting these protein domains was to *predict temperate phages*, ergo I don't even want a predictor of lytic phages in my dataset and given the choice of protein domains that I am including believe that these would likely be noise.\n",
    "\n",
    "**Note that this step is reasonable if I *only* consider the training set in making this decision, as I am doing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running count of uninformative columns: 55\n",
      "Running count of uninformative columns: 165\n"
     ]
    }
   ],
   "source": [
    "uninformative_cols = []\n",
    "###Use training set to remove certain cases with too few hits (likely unreliable/not useful)\n",
    "too_few_count = 2\n",
    "transpose_df = ml_df_train.transpose()\n",
    "uninformative_cols.extend(list(transpose_df[transpose_df.sum(axis=1)<=too_few_count].index))\n",
    "print('Running count of uninformative columns:', len(uninformative_cols))\n",
    "###Cases where lytic features are higher than or equal to temperate\n",
    "lysog_df = ml_df_train[train_df['Temperate (empirical)']=='yes'].transpose()\n",
    "lytic_df = ml_df_train[train_df['Temperate (empirical)']=='no'].transpose()\n",
    "uninformative_cols.extend(list(transpose_df[lysog_df.sum(axis=1) <= (lytic_df.sum(axis=1))].index))\n",
    "uninformative_cols = list(set(uninformative_cols))\n",
    "print('Running count of uninformative columns:', len(uninformative_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop these columns from train, test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape (634, 206)\n",
      "Testing set shape (423, 206)\n"
     ]
    }
   ],
   "source": [
    "ml_df_train = ml_df_train.drop(columns=uninformative_cols)\n",
    "print('Training set shape', ml_df_train.shape)\n",
    "\n",
    "ml_df_test = ml_df_test.drop(columns=uninformative_cols)\n",
    "print('Testing set shape', ml_df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write training and testing dataframes to a file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(columns=uninformative_cols).to_csv('../../Data/train_df.csv')\n",
    "test_df.drop(columns=uninformative_cols).to_csv('../../Data/test_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning of a model\n",
    "\n",
    "1) Random forest \n",
    "\n",
    "2) Hyper-parameter optimization via training-validation set cross-validation\n",
    "    1. normal k-fold cross-validation\n",
    "        - where best is the highest mean amongst cross-val scores (standard approach)\n",
    "    2. my more intense bootstrap sampling version\n",
    "        - where best is the highest minimum amongst cross-val scores (my interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of best model: {'bootstrap': False, 'class_weight': 'balanced_subsample', 'max_depth': 22, 'min_samples_leaf': 1, 'n_estimators': 20}\n",
      "Cross validation scores using that model: [0.95714286 0.99310345 0.97222222 0.98611111 0.95833333]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../../Data/rf_best.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Really simple random forest hyper-parameter sweep\n",
    "scoring_fxn = 'f1'\n",
    "n_fold_cv = 5\n",
    "#\n",
    "rf = RandomForestClassifier()\n",
    "params_rf = {'bootstrap': [True, False],\\\n",
    "             'class_weight':['balanced', 'balanced_subsample'],\\\n",
    "             'min_samples_leaf': [1, 2],\\\n",
    "             'n_estimators': list(range(10, 105, 5)),\\\n",
    "             'max_depth': list(range(10, 42, 2))}\n",
    "\n",
    "rf_gs = GridSearchCV(rf, params_rf, scoring=scoring_fxn, cv=n_fold_cv)\n",
    "\n",
    "#Fit the model\n",
    "rf_gs.fit(ml_df_train, training_labels['binary'])\n",
    "\n",
    "#Select the best model (this selects the parameter set with the best mean score across cv splits)\n",
    "rf_best = rf_gs.best_estimator_\n",
    "print('Parameters of best model:', rf_gs.best_params_)\n",
    "\n",
    "print('Cross validation scores using that model:',\\\n",
    "      cross_val_score(rf_gs.best_estimator_, ml_df_train, training_labels['binary'],\\\n",
    "                cv=n_fold_cv, scoring=scoring_fxn))\n",
    "\n",
    "joblib.dump(rf_best, '../../Data/rf_best.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set results:\n",
      "1    364\n",
      "0    270\n",
      "Name: binary, dtype: int64\n",
      "\n",
      "[[270   0]\n",
      " [  1 363]]\n",
      "0.998422712933754\n"
     ]
    }
   ],
   "source": [
    "print('Training set results:')\n",
    "print(training_labels['binary'].value_counts()) ### 1 is for temperate, 0 for lytic\n",
    "assert list(training_labels.index) == list(ml_df_train.index)\n",
    "print()\n",
    "print(confusion_matrix(training_labels['binary'], rf_best.predict(ml_df_train)))\n",
    "print(accuracy_score(training_labels['binary'], rf_best.predict(ml_df_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set results:\n",
      "1    240\n",
      "0    183\n",
      "Name: binary, dtype: int64\n",
      "\n",
      "[[181   2]\n",
      " [  6 234]]\n",
      "0.9810874704491725\n"
     ]
    }
   ],
   "source": [
    "print('Testing set results:')\n",
    "print(testing_labels['binary'].value_counts()) ### 1 is for temperate, 0 for lytic\n",
    "assert list(testing_labels.index) == list(ml_df_test.index)\n",
    "print()\n",
    "print(confusion_matrix(testing_labels['binary'], rf_best.predict(ml_df_test)))\n",
    "print(accuracy_score(testing_labels['binary'], rf_best.predict(ml_df_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous run/s said 1 error and 1,7 errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving cross-validation with pre-defined arrays of indices and repeated cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 2 528 106\n"
     ]
    }
   ],
   "source": [
    "###Pre-defining n separate train/test splits\n",
    "n_repetitions = 20\n",
    "train_frac = 0.5/0.6 ###This essentially defines the training and validation set sizes\n",
    "\n",
    "###This works by selecting iloc's\n",
    "listy = list(range(0, ml_df_train.shape[0]))\n",
    "train_lists = []\n",
    "val_lists = []\n",
    "for i in range(n_repetitions):\n",
    "    random.Random(42+i).shuffle(listy)\n",
    "    train_lists.append(listy[:int(len(listy)*train_frac)]) ###Select from beginning of list up to cut-point\n",
    "    val_lists.append(listy[int(len(listy)*train_frac):]) ###Select cut-point onwards\n",
    "###Zip these two together (and make sure I did it correctly)\n",
    "cv_splits = list(zip(train_lists, val_lists))\n",
    "print(len(cv_splits), len(cv_splits[0]), len(cv_splits[0][0]), len(cv_splits[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2432 20\n",
      "2432 2\n",
      "2432 2\n",
      "({'bootstrap': False, 'class_weight': 'balanced', 'max_depth': 14, 'min_samples_leaf': 2, 'n_estimators': 10}, (0.9256198347107438, 0.9606299212598426, 0.99009900990099, 0.9747899159663865, 0.9739130434782608, 0.975609756097561, 0.9843749999999999, 0.9821428571428572, 1.0, 0.9743589743589743, 0.9557522123893805, 0.9615384615384615, 0.9636363636363636, 0.9655172413793104, 0.9767441860465117, 0.970873786407767, 0.9908256880733944, 0.9836065573770492, 0.9752066115702479, 0.9649122807017544))\n",
      "({'bootstrap': False, 'class_weight': 'balanced_subsample', 'max_depth': 40, 'min_samples_leaf': 1, 'n_estimators': 95}, (0.959349593495935, 0.9606299212598426, 0.99009900990099, 0.9747899159663865, 0.9739130434782608, 0.975609756097561, 0.9921259842519685, 0.9911504424778761, 1.0, 0.983050847457627, 0.9734513274336283, 0.9714285714285714, 0.972972972972973, 0.9743589743589743, 0.9846153846153847, 0.9807692307692307, 0.9908256880733944, 0.991869918699187, 0.9752066115702479, 0.9649122807017544))\n"
     ]
    }
   ],
   "source": [
    "###Perform grid search using all the same parameters as previosly defined\n",
    "rf_AJH = RandomForestClassifier()\n",
    "rf_gs_AJH = GridSearchCV(rf_AJH, params_rf, scoring=scoring_fxn, cv=cv_splits) ###Provide cv with list\n",
    "\n",
    "#Fit the model\n",
    "rf_gs_AJH.fit(ml_df_train.values, training_labels['binary'].values) ###Run on the values\n",
    "\n",
    "###Find the model with the highest minimum accuracy across all n_repetitions of cross-validation\n",
    "listy = list(zip(*[rf_gs_AJH.cv_results_['split{}_test_score'.format(i)] for i in range(n_repetitions)]))\n",
    "print(len(listy), len(listy[0]))\n",
    "listy = list(zip(*[rf_gs_AJH.cv_results_['params'], listy]))\n",
    "print(len(listy), len(listy[0]))\n",
    "listy = sorted(listy, key=lambda x: min(x[1]))\n",
    "print(len(listy), len(listy[0]))\n",
    "print(listy[0])\n",
    "print(listy[-1])\n",
    "best_params = listy[-1][0]\n",
    "rf_min_AJH = RandomForestClassifier(**best_params)\n",
    "rf_min_AJH.fit(ml_df_train, training_labels['binary'])\n",
    "\n",
    "joblib.dump(rf_min_AJH, '../../Data/rf_highMinAJH.joblib'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    364\n",
      "0    270\n",
      "Name: binary, dtype: int64\n",
      "[[270   0]\n",
      " [  1 363]]\n",
      "0.998422712933754\n"
     ]
    }
   ],
   "source": [
    "print(training_labels['binary'].value_counts()) ### 1 is for temperate, 0 for lytic\n",
    "assert list(training_labels.index) == list(ml_df_train.index)\n",
    "print(confusion_matrix(training_labels['binary'].values, rf_min_AJH.predict(ml_df_train.values)))\n",
    "print(accuracy_score(training_labels['binary'].values, rf_min_AJH.predict(ml_df_train.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    240\n",
      "0    183\n",
      "Name: binary, dtype: int64\n",
      "[[182   1]\n",
      " [  7 233]]\n",
      "0.9810874704491725\n"
     ]
    }
   ],
   "source": [
    "print(testing_labels['binary'].value_counts()) ### 1 is for temperate, 0 for lytic\n",
    "assert list(testing_labels.index) == list(ml_df_test.index)\n",
    "print(confusion_matrix(testing_labels['binary'], rf_min_AJH.predict(ml_df_test)))\n",
    "print(accuracy_score(testing_labels['binary'], rf_min_AJH.predict(ml_df_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous run said 1 wrong and 1/7 wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare prediction errors on the training set to previous benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = rf_best\n",
    "\n",
    "predict_array = rf_model.predict(ml_df_train.values)\n",
    "train_df['my_predictions'] = predict_array\n",
    "train_df.at[train_df[train_df['my_predictions']==1].index, 'my_predictions_str']= 'yes'\n",
    "train_df.at[train_df[train_df['my_predictions']==0].index, 'my_predictions_str']= 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Previous wrong predictions:', train_df[train_df['Temperate (empirical)'] !=\\\n",
    "               train_df['Temperate (bioinformatically predicted)']].shape[0])\n",
    "\n",
    "\n",
    "print(confusion_matrix(train_df['Temperate (empirical)'],\\\n",
    "                       train_df['Temperate (bioinformatically predicted)']))\n",
    "\n",
    "print('Wrong predictions from my model:', train_df[train_df['Temperate (empirical)'] !=\\\n",
    "                                                   train_df['my_predictions_str']].shape[0])\n",
    "\n",
    "print(confusion_matrix(train_df['Temperate (empirical)'],\\\n",
    "                 train_df['my_predictions_str']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Look at the error/s**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df['Temperate (empirical)'] !=train_df['my_predictions_str']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And now that we're fully finished model fitting, look at the test set predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_array = rf_model.predict(ml_df_test.values)\n",
    "test_df['my_predictions'] = predict_array\n",
    "test_df.at[test_df[test_df['my_predictions']==1].index, 'my_predictions_str']= 'yes'\n",
    "test_df.at[test_df[test_df['my_predictions']==0].index, 'my_predictions_str']= 'no'\n",
    "\n",
    "print('Previous wrong predictions:', test_df[test_df['Temperate (empirical)'] !=\\\n",
    "               test_df['Temperate (bioinformatically predicted)']].shape[0])\n",
    "\n",
    "print(confusion_matrix(test_df['Temperate (empirical)'],\\\n",
    "                 test_df['Temperate (bioinformatically predicted)']))\n",
    "\n",
    "print('Wrong predictions from my model:', test_df[test_df['Temperate (empirical)'] !=\\\n",
    "                                                   test_df['my_predictions_str']].shape[0])\n",
    "\n",
    "print(confusion_matrix(test_df['Temperate (empirical)'],\\\n",
    "                 test_df['my_predictions_str']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Look at the errors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[test_df['Temperate (empirical)'] !=test_df['my_predictions_str']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate the source of errors\n",
    "\n",
    "Are any lytic and temperate vectors actually identical?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lyt_vecs = []\n",
    "train_lyt = ml_df_train.loc[training_labels[training_labels['binary']==0].index].values\n",
    "test_lyt = ml_df_test.loc[testing_labels[testing_labels['binary']==0].index].values\n",
    "lyt_vecs = np.concatenate((train_lyt, test_lyt))\n",
    "\n",
    "train_temp = ml_df_train.loc[training_labels[training_labels['binary']==1].index].values\n",
    "test_temp = ml_df_test.loc[testing_labels[testing_labels['binary']==1].index].values\n",
    "temp_vecs = np.concatenate((train_temp, test_temp))\n",
    "print('Number of total entries (lytic, temperate):', lyt_vecs.shape[0], temp_vecs.shape[0])\n",
    "\n",
    "temp_set = set([tuple(i) for i in temp_vecs])\n",
    "lyt_set = set([tuple(i) for i in lyt_vecs])\n",
    "print('Number of unique vectors (lytic, temperate):', len(lyt_set), len(temp_set))\n",
    "\n",
    "print('Set intersection:', len(temp_set.intersection(lyt_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "growing_df['pfam00665'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "growing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(rf_best.feature_importances_, 20, cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(rf_best.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([i for i in rf_best.feature_importances_ if i == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zippy = list(zip(rf_best.feature_importances_, ml_df_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in zippy:\n",
    "    if i == 0:\n",
    "        uninformative_cols.append(j)\n",
    "uninformative_cols = list(set(uninformative_cols))\n",
    "print(len(uninformative_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_df = pd.read_csv('../Data/cdd/cddid_extension_2020_4_4.tsv', sep='\\t', index_col=0)\n",
    "domain_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(domain_df['1']), len(set(domain_df['1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_domain_df = domain_df[domain_df['1'].isin(uninformative_cols)]\n",
    "good_domain_df = domain_df[domain_df['1'].isin(uninformative_cols)==False]\n",
    "print(bad_domain_df.shape, good_domain_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_domain_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_col = 'temperate'\n",
    "bad_domain_df[test_col].sum(), good_domain_df[test_col].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_col = 'integrase'\n",
    "bad_domain_df[bad_domain_df[test_col]==1]['3']\n",
    "# good_domain_df[good_domain_df[test_col]==1]['3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cols = []\n",
    "running_sum = 0\n",
    "for i,j in zippy:\n",
    "    if i > 0.0085:\n",
    "        best_cols.append(j)\n",
    "        running_sum += i\n",
    "print(len(best_cols))\n",
    "print(running_sum)\n",
    "\n",
    "best_domain_df = domain_df[domain_df['1'].isin(best_cols)]\n",
    "best_domain_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_domain_df[(best_domain_df['search_hits']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use = list(best_domain_df['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feature_train_df = ml_df_train[cols_to_use]\n",
    "best_feature_test_df = ml_df_test[cols_to_use]\n",
    "best_feature_challenge_df = ml_df_challenge[cols_to_use]\n",
    "print(best_feature_train_df.shape, best_feature_test_df.shape, best_feature_challenge_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Really simple random forest hyper-parameter sweep\n",
    "# scoring_fxn = 'accuracy'\n",
    "scoring_fxn = 'f1'\n",
    "# scoring_fxn = 'average_precision'\n",
    "\n",
    "n_fold_cv = 5\n",
    "\n",
    "rf_truncate = RandomForestClassifier()\n",
    "params_rf = {'bootstrap': [True, False],\\\n",
    "             'class_weight':['balanced', 'balanced_subsample'],\\\n",
    "             'n_estimators': list(range(2, 22, 2)),\\\n",
    "             'max_depth': list(range(6, 22, 2))}\n",
    "rf_gs_truncate = GridSearchCV(rf_truncate, params_rf, scoring=scoring_fxn, cv=n_fold_cv)\n",
    "\n",
    "#Fit the model\n",
    "rf_gs_truncate.fit(best_feature_train_df, training_labels['binary'])\n",
    "\n",
    "#Select the best model (this selects the best mean cv score and I'm skeptical that's the right choice)\n",
    "rf_best_truncate = rf_gs_truncate.best_estimator_\n",
    "print(rf_gs_truncate.best_params_)\n",
    "\n",
    "print(cross_val_score(rf_gs_truncate.best_estimator_, best_feature_train_df, training_labels['binary'],\\\n",
    "                cv=n_fold_cv, scoring=scoring_fxn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_labels['binary'].value_counts()) ### 1 is for temperate, 0 for lytic\n",
    "assert list(training_labels.index) == list(best_feature_train_df.index)\n",
    "print(confusion_matrix(training_labels['binary'], rf_best_truncate.predict(best_feature_train_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(334+258)/(334+258+6+21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testing_labels['binary'].value_counts()) ### 1 is for temperate, 0 for lytic\n",
    "assert list(testing_labels.index) == list(best_feature_test_df.index)\n",
    "print(confusion_matrix(testing_labels['binary'], rf_best_truncate.predict(best_feature_test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(challenge_labels['binary'].value_counts()) ### 1 is for temperate, 0 for lytic\n",
    "assert list(challenge_labels.index) == list(best_feature_challenge_df.index)\n",
    "print(confusion_matrix(challenge_labels['binary'], rf_best_truncate.predict(best_feature_challenge_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicted_useless_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_test = '../Data/cdd/2020_4_1_useless_cdd.tsv'\n",
    "feature_df = pd.read_csv(file_to_test, sep='\\t', header=None, index_col=0)\n",
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = 0\n",
    "listy = list(feature_df[1])\n",
    "for i in uninformative_cols:\n",
    "    if i in listy:\n",
    "        counts += 1\n",
    "print(counts)\n",
    "# len(set(uninformative_cols) - set(feature_df[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listy = list(feature_df[feature_df[3].str.contains('lysogen', case=False)][1])\n",
    "counts = 0\n",
    "for i in listy:\n",
    "    if i in uninformative_cols:\n",
    "        counts += 1\n",
    "print(counts/len(listy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "too_few_df[too_few_df.columns[18:22]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi, p, dof, ex = stats.chi2_contingency([[1, 630-1], [5, 421-5]])\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats import contingency_tables\n",
    "print(contingency_tables.StratifiedTable([[[177, 1], [4, 239]], [[275, 0], [1, 354]]]).test_equal_odds().pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../../Data/model_data/clusters.json', 'r') as infile:\n",
    "    clusters = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['name'] = ''  \n",
    "full_df.at[full_df[full_df['Database source'] == 'NCBI RefSeq'].index, 'name'] =\\\n",
    "                    full_df[full_df['Database source'] == 'NCBI RefSeq']['RefSeq accession number']\n",
    "full_df.at[full_df[full_df['Database source'] == 'Actinobacteriophage_785'].index, 'name'] =\\\n",
    "                    full_df[full_df['Database source'] == 'Actinobacteriophage_785']['Virus identifier used for the analysis'].str.split('_').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(634, 394)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(634, 394)\n"
     ]
    }
   ],
   "source": [
    "temp_df = full_df.loc[train_df.index]\n",
    "print(temp_df.shape)\n",
    "temp_df_names = list(temp_df['name'])\n",
    "\n",
    "independent_set = []\n",
    "for cluster in clusters:\n",
    "    hits = []\n",
    "    for member in cluster:\n",
    "        if member in temp_df_names:\n",
    "            hits.append(member)\n",
    "    if len(hits) == 0:\n",
    "        independent_set.extend(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(172, 394)\n"
     ]
    }
   ],
   "source": [
    "temp_df = full_df.loc[test_df.index]\n",
    "temp_df = temp_df[temp_df['name'].isin(independent_set)]\n",
    "print(temp_df.shape)\n",
    "indices = temp_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72  1]\n",
      " [ 6 93]]\n",
      "0.9593023255813954\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(testing_labels.loc[indices]['binary'], rf_min_AJH.predict(ml_df_test.loc[indices])))\n",
    "print(accuracy_score(testing_labels.loc[indices]['binary'], rf_min_AJH.predict(ml_df_test.loc[indices])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Virus identifier used for the analysis</th>\n",
       "      <th>Database source</th>\n",
       "      <th>RefSeq header source description</th>\n",
       "      <th>RefSeq accession number</th>\n",
       "      <th>Genome type</th>\n",
       "      <th>Order</th>\n",
       "      <th>Family</th>\n",
       "      <th>Host domain</th>\n",
       "      <th>Host phylum</th>\n",
       "      <th>Host class</th>\n",
       "      <th>...</th>\n",
       "      <th>pfam18763</th>\n",
       "      <th>pfam18802</th>\n",
       "      <th>pfam18803</th>\n",
       "      <th>pfam18804</th>\n",
       "      <th>pfam18866</th>\n",
       "      <th>smart00470</th>\n",
       "      <th>smart00597</th>\n",
       "      <th>smart00614</th>\n",
       "      <th>smart00674</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>kbnp1711__nc_023593</td>\n",
       "      <td>NCBI RefSeq</td>\n",
       "      <td>Escherichia phage KBNP1711</td>\n",
       "      <td>NC_023593</td>\n",
       "      <td>dsDNA</td>\n",
       "      <td>Caudovirales</td>\n",
       "      <td>Podoviridae</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NC_023593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>615</td>\n",
       "      <td>flagstaff__actino785</td>\n",
       "      <td>Actinobacteriophage_785</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>dsDNA</td>\n",
       "      <td>Caudovirales</td>\n",
       "      <td>Siphoviridae</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>flagstaff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>a-4l__nc_024358</td>\n",
       "      <td>NCBI RefSeq</td>\n",
       "      <td>Anabaena phage A-4L</td>\n",
       "      <td>NC_024358</td>\n",
       "      <td>dsDNA</td>\n",
       "      <td>Caudovirales</td>\n",
       "      <td>Podoviridae</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Cyanobacteria</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NC_024358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>418</td>\n",
       "      <td>cp-t1__nc_019457</td>\n",
       "      <td>NCBI RefSeq</td>\n",
       "      <td>Vibrio phage CP-T1 (vB_VchM-CP-T1)</td>\n",
       "      <td>NC_019457</td>\n",
       "      <td>dsDNA</td>\n",
       "      <td>Caudovirales</td>\n",
       "      <td>Myoviridae</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NC_019457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1999</td>\n",
       "      <td>sumu__nc_019455</td>\n",
       "      <td>NCBI RefSeq</td>\n",
       "      <td>Haemophilus phage SuMu</td>\n",
       "      <td>NC_019455</td>\n",
       "      <td>dsDNA</td>\n",
       "      <td>Caudovirales</td>\n",
       "      <td>Myoviridae</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NC_019455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>7201__nc_002185</td>\n",
       "      <td>NCBI RefSeq</td>\n",
       "      <td>Streptococcus phage 7201</td>\n",
       "      <td>NC_002185</td>\n",
       "      <td>dsDNA</td>\n",
       "      <td>Caudovirales</td>\n",
       "      <td>Siphoviridae</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacilli</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NC_002185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1463</td>\n",
       "      <td>phieco32__nc_010324</td>\n",
       "      <td>NCBI RefSeq</td>\n",
       "      <td>Enterobacteria phage Phieco32</td>\n",
       "      <td>NC_010324</td>\n",
       "      <td>dsDNA</td>\n",
       "      <td>Caudovirales</td>\n",
       "      <td>Podoviridae</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NC_010324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1144</td>\n",
       "      <td>nj01__nc_018835</td>\n",
       "      <td>NCBI RefSeq</td>\n",
       "      <td>Enterobacteria phage NJ01</td>\n",
       "      <td>NC_018835</td>\n",
       "      <td>dsDNA</td>\n",
       "      <td>Caudovirales</td>\n",
       "      <td>Podoviridae</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NC_018835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1872</td>\n",
       "      <td>sfi19__nc_000871</td>\n",
       "      <td>NCBI RefSeq</td>\n",
       "      <td>Streptococcus phage Sfi19</td>\n",
       "      <td>NC_000871</td>\n",
       "      <td>dsDNA</td>\n",
       "      <td>Caudovirales</td>\n",
       "      <td>Siphoviridae</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacilli</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NC_000871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1495</td>\n",
       "      <td>phikz__nc_004629</td>\n",
       "      <td>NCBI RefSeq</td>\n",
       "      <td>Pseudomonas phage phiKZ</td>\n",
       "      <td>NC_004629</td>\n",
       "      <td>dsDNA</td>\n",
       "      <td>Caudovirales</td>\n",
       "      <td>Myoviridae</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NC_004629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>cambiare__actino785</td>\n",
       "      <td>Actinobacteriophage_785</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>dsDNA</td>\n",
       "      <td>Caudovirales</td>\n",
       "      <td>Siphoviridae</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cambiare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>b3__nc_006548</td>\n",
       "      <td>NCBI RefSeq</td>\n",
       "      <td>Pseudomonas phage B3</td>\n",
       "      <td>NC_006548</td>\n",
       "      <td>dsDNA</td>\n",
       "      <td>Caudovirales</td>\n",
       "      <td>Siphoviridae</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NC_006548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Virus identifier used for the analysis          Database source  \\\n",
       "890                     kbnp1711__nc_023593              NCBI RefSeq   \n",
       "615                    flagstaff__actino785  Actinobacteriophage_785   \n",
       "109                         a-4l__nc_024358              NCBI RefSeq   \n",
       "418                        cp-t1__nc_019457              NCBI RefSeq   \n",
       "1999                        sumu__nc_019455              NCBI RefSeq   \n",
       "90                          7201__nc_002185              NCBI RefSeq   \n",
       "1463                    phieco32__nc_010324              NCBI RefSeq   \n",
       "1144                        nj01__nc_018835              NCBI RefSeq   \n",
       "1872                       sfi19__nc_000871              NCBI RefSeq   \n",
       "1495                       phikz__nc_004629              NCBI RefSeq   \n",
       "352                     cambiare__actino785  Actinobacteriophage_785   \n",
       "216                           b3__nc_006548              NCBI RefSeq   \n",
       "\n",
       "        RefSeq header source description RefSeq accession number Genome type  \\\n",
       "890           Escherichia phage KBNP1711               NC_023593       dsDNA   \n",
       "615                       not applicable          not applicable       dsDNA   \n",
       "109                  Anabaena phage A-4L               NC_024358       dsDNA   \n",
       "418   Vibrio phage CP-T1 (vB_VchM-CP-T1)               NC_019457       dsDNA   \n",
       "1999              Haemophilus phage SuMu               NC_019455       dsDNA   \n",
       "90              Streptococcus phage 7201               NC_002185       dsDNA   \n",
       "1463       Enterobacteria phage Phieco32               NC_010324       dsDNA   \n",
       "1144           Enterobacteria phage NJ01               NC_018835       dsDNA   \n",
       "1872           Streptococcus phage Sfi19               NC_000871       dsDNA   \n",
       "1495             Pseudomonas phage phiKZ               NC_004629       dsDNA   \n",
       "352                       not applicable          not applicable       dsDNA   \n",
       "216                 Pseudomonas phage B3               NC_006548       dsDNA   \n",
       "\n",
       "             Order        Family Host domain     Host phylum  \\\n",
       "890   Caudovirales   Podoviridae    Bacteria  Proteobacteria   \n",
       "615   Caudovirales  Siphoviridae    Bacteria  Actinobacteria   \n",
       "109   Caudovirales   Podoviridae    Bacteria   Cyanobacteria   \n",
       "418   Caudovirales    Myoviridae    Bacteria  Proteobacteria   \n",
       "1999  Caudovirales    Myoviridae    Bacteria  Proteobacteria   \n",
       "90    Caudovirales  Siphoviridae    Bacteria      Firmicutes   \n",
       "1463  Caudovirales   Podoviridae    Bacteria  Proteobacteria   \n",
       "1144  Caudovirales   Podoviridae    Bacteria  Proteobacteria   \n",
       "1872  Caudovirales  Siphoviridae    Bacteria      Firmicutes   \n",
       "1495  Caudovirales    Myoviridae    Bacteria  Proteobacteria   \n",
       "352   Caudovirales  Siphoviridae    Bacteria  Actinobacteria   \n",
       "216   Caudovirales  Siphoviridae    Bacteria  Proteobacteria   \n",
       "\n",
       "               Host class  ... pfam18763 pfam18802 pfam18803 pfam18804  \\\n",
       "890   Gammaproteobacteria  ...         0         0         0         0   \n",
       "615        Actinobacteria  ...         0         1         1         0   \n",
       "109           Unspecified  ...         0         0         1         0   \n",
       "418   Gammaproteobacteria  ...         0         0         0         0   \n",
       "1999  Gammaproteobacteria  ...         0         0         0         0   \n",
       "90                Bacilli  ...         0         0         0         0   \n",
       "1463  Gammaproteobacteria  ...         0         0         0         0   \n",
       "1144  Gammaproteobacteria  ...         0         0         0         0   \n",
       "1872              Bacilli  ...         0         0         0         0   \n",
       "1495  Gammaproteobacteria  ...         0         0         0         0   \n",
       "352        Actinobacteria  ...         0         1         1         0   \n",
       "216   Gammaproteobacteria  ...         0         0         0         0   \n",
       "\n",
       "     pfam18866  smart00470  smart00597 smart00614 smart00674       name  \n",
       "890          0           0           0          0          0  NC_023593  \n",
       "615          0           0           0          0          0  flagstaff  \n",
       "109          0           0           0          0          0  NC_024358  \n",
       "418          0           0           0          0          0  NC_019457  \n",
       "1999         0           0           0          0          0  NC_019455  \n",
       "90           0           0           0          0          0  NC_002185  \n",
       "1463         0           0           0          0          0  NC_010324  \n",
       "1144         0           0           0          0          0  NC_018835  \n",
       "1872         0           0           0          0          0  NC_000871  \n",
       "1495         0           0           0          0          0  NC_004629  \n",
       "352          0           0           0          0          0   cambiare  \n",
       "216          0           0           0          0          0  NC_006548  \n",
       "\n",
       "[12 rows x 394 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = full_df.loc[indices]\n",
    "temp_df[temp_df['Temperate (empirical)'] != temp_df['Temperate (bioinformatically predicted)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9302325581395349"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-12/len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
